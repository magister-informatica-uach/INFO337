{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia estadística con tests no-paramétricos\n",
    "\n",
    "Hagamos un breve recordatorio de las lecciones anteriores para motivar este tema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo (recordatorio) de inferencia con test paramétrico\n",
    "\n",
    "Digamos por ejemplo que queremos estimar los parámetros $\\mu$ y $\\sigma^2$ de la población\n",
    "\n",
    "Colectamos nuestras muestras (observaciones) y construimos una estadístico muestral: \n",
    "\n",
    "$$\n",
    "\\bar X = \\sum_i X_i/N\n",
    "$$\n",
    "\n",
    "Si **asumimos** que la población se distribuye normal entonces: $\\bar X = \\mathcal{N}(\\mu, \\sigma^2/N)$, es decir que \n",
    "- En promedio la media muestral equivale a la media de la población\n",
    "- A mayor número de muestras menor es la varianza de nuestro estimador\n",
    "\n",
    "Luego, para tomar decisiones basados en $\\bar X$, usamos un estadístico de test: \n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar X - \\mu}{\\sqrt{\\hat \\sigma^2/N}}\n",
    "$$ \n",
    "\n",
    "(o estadístico Z si $\\sigma$ es conocido)\n",
    "\n",
    "Dado que conocemos la distribución de $\\bar X$ podemos calcular la distribución de $t$ bajo la hipótesis nula (e.g. $\\mu=0$) y calcular el p-value \n",
    "\n",
    "> p-value: pbb de observar un valor más grande que t si la hipótesis nula fuera cierta\n",
    "\n",
    "### El análisis descansa en los supuestos sobre la distribución de la población\n",
    "\n",
    "¿Qué ocurre en el ejemplo anterior si el supuesto sobre la distribución de la población estaba equivocado?\n",
    "\n",
    "La distribución muestral será erronea, la distribución nula será erronea y el p-value será erroneo\n",
    "\n",
    "### Horror ¿Qué hago?\n",
    "\n",
    "1. (Mantén la calma)\n",
    "1. En la práctica los tests parámetricos funcionan ante \"ligeras\" desviaciones de los supuestos\n",
    "1. Podemos **comprobar** los supuestos antes de hacer el análisis\n",
    "1. Si los supuestos no se cumplen podemos usar **inferencia no paramétrica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando normalidad con test no-paraḿetrico\n",
    "\n",
    "La normalidad es un supuesto en muchos procedimientos parámetricos, por ejemplo: t-test, ANOVA, regresion lineal\n",
    "\n",
    "Tengamos en cuanta las características principales de la distribución normal\n",
    "\n",
    "- Unimodal con media igual a su moda\n",
    "- Simétrica en torno a la media\n",
    "- Concentrada en torno a la media: ~68% a $\\pm \\sigma$, ~95% a $\\pm 2\\sigma$, ...\n",
    "\n",
    "Si tenemos suficientes muestras podriamos observar el histograma y comprobar visualmente si esto se cumple\n",
    "\n",
    "Observe las siguientes distribuciones, ¿Cuáles son no-normales? ¿Cuál o cuáles características de la distribución normal no se están cumpliendo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = scipy.stats.norm(loc=4, scale=2).rvs(1000)\n",
    "data2 = scipy.stats.gamma(a=2, scale=1).rvs(1000)\n",
    "data3 = scipy.stats.uniform(loc=2, scale=1).rvs(1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(7, 2.5), tight_layout=True)\n",
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    #data = (data - np.mean(data))/np.std(data)\n",
    "    ax[i].hist(data, bins=10, density=True)\n",
    "    ax[i].set_xlabel('data'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentos estadísticos de la distribución normal\n",
    "\n",
    "En el caso particular de la normal sabemos que el tercer momento (simetría) debiese ser cero\n",
    "\n",
    "Podemos calcular la simetría usando [`scipy.stats.skew`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html), para el caso particular de la normal puede ser util [`scipy.stats.skewtest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    display(scipy.stats.skew(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cuarto momento (kurtosis) también tiene un valor particular en el caso de la distribución normal\n",
    "\n",
    "La función [`scipy.stats.kurtosis`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html) tiene dos definiciones de Kurtosis\n",
    "\n",
    "La definición por defecto (Fisher) nos da cero en el caso de que la distribución sea normal\n",
    "\n",
    "Puede ser también util [`scipy.stats.kurtosistest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosistest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    display(scipy.stats.kurtosis(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability plots (PP)\n",
    "\n",
    "Otra opción gráfica son los *probability plots* \n",
    "\n",
    "Se calculan los cuantiles (qq) o percentiles (pp) de dos muestras **o** de una muestra y una distribución teórica\n",
    "\n",
    "Luego se grafica uno en función del otro. Mientras más se parezca el resultado a una linea recta más similares son las distribuciones\n",
    "\n",
    "Podemos usar [`scipy.stats.probplot`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html#scipy.stats.probplot) para comparar una muestra con una distribución teórica \n",
    "\n",
    "- En este caso la distribución teórica será la normal estándar\n",
    "- Dado que la prueba es basada en rangos no necesitamos entregar parámetros de localización (media) o escala (varianza)\n",
    "- Cualquier parámetro de otro tipo (shape) se debe indicar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(7, 2.5), tight_layout=True)\n",
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    #data = ((data - np.mean(data))/np.std(data)).copy()\n",
    "    (osm, osr), (w, b, r2) = scipy.stats.probplot(data, dist=\"norm\", fit=True);\n",
    "    ax[i].plot(osm, osr)\n",
    "    ax[i].plot(np.arange(-3, 4), np.arange(-3, 4)*w + b, 'k--', alpha=0.25)\n",
    "    ax[i].set_title('data'+str(i));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test no-paramétrico de Kolmogorov-Smirnov (KS)\n",
    "\n",
    "Este test examina la distancia entre las funciones de distribución acumulada (CDF) de dos muestras. Es un test no parámetrico, es decir que no asume una distribución particular para las muestras. Solo se puede usar para distribuciones univariadas continuas\n",
    "\n",
    "- Si se compara una muestra empírica con una CDF teórica: Test de KS de una muestra\n",
    "- Si se comparan dos muestras empíricas: Test de KS de dos muestras\n",
    "\n",
    "\n",
    "#### Caso de una muestra\n",
    "\n",
    "El estadístico de test para KS es\n",
    "\n",
    "$$\n",
    "D_n = \\sup_x |F_n(x) - F(x)|\n",
    "$$\n",
    "\n",
    "donde $F(x) = \\int_{-\\infty}^x f(x) dx = P(X<x)$ es la CDF teórica y \n",
    "\n",
    "$$\n",
    "F_n(x) = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}[X_i<x]\n",
    "$$\n",
    "\n",
    "es la distribución acumulada empírica (ECDF)\n",
    "\n",
    "Veamos como se ve la ECDF de las tres muestras anteriores contra la CDF de una normal estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    n = x.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return(x,y)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(7, 2.5), tight_layout=True)\n",
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    # ECDF\n",
    "    data = ((data - np.mean(data))/np.std(data)).copy() \n",
    "    x, y = ecdf(data)\n",
    "    ax[i].plot(x, y)\n",
    "    # CDF standard normal\n",
    "    x_t = np.linspace(np.amin(data), np.amax(data), num=100)\n",
    "    y_t = scipy.stats.norm.cdf(x_t)    \n",
    "    ax[i].plot(x_t, y_t, 'k--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $D_n$ es la distancia más larga entre todas las distancias de la CDF teórica y empírica\n",
    "\n",
    "Las hipótesis de la prueba KS de una muestra son\n",
    "\n",
    "- $\\mathcal{H}_0$: Los datos siguen la distribución teórica especificada\n",
    "- $\\mathcal{H}_A$: Los datos no siguen la distribución teórica especificada\n",
    "\n",
    "Si $D_n$ es menor que el valor crítico no podemos rechazar $H_0$\n",
    "\n",
    "Podemos usar [`scipy.stats.kstest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html#scipy.stats.kstest) para probar nuestros datos contra la distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    data = ((data - np.mean(data))/np.std(data)).copy()\n",
    "    Dn, pvalue = scipy.stats.kstest(data, scipy.stats.norm.cdf) #Acepta una cdf o un string, e.g. 'norm'\n",
    "    print(i, Dn, pvalue)\n",
    "    if pvalue < 0.05:\n",
    "        display(\"Rechazo la hipótesis nula: nuestros datos no siguen la distribución especificada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas de Kolmogorov-Smirnov\n",
    "\n",
    "- Solo sirve para distribuciones continuas y univariadas\n",
    "- Es más sensible en el centro que en las colas de la distribución\n",
    "- Se debe especificar completamente la distribución teórica\n",
    "\n",
    "#### Opciones\n",
    "\n",
    "Si mi distribución es discreta: Test de chi cuadrado\n",
    "\n",
    "Mejoras de KS que le da más ponderación a las colas:\n",
    "- [Test de Anderson-Darling](https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm), con implementación en [`scipy.stats.anderson`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.html)  (normal, exponencial y gumbel)\n",
    "- [Test de Shapiro-Wilks](https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm) test con implementación en [`scipy.stats.shapiro`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html) (solo normal)\n",
    "\n",
    "Si se quiere probar normalidad pero no se sabe la media o la varianza se puede usar el test de [Lilliefors](https://www.statsmodels.org/0.6.1/generated/statsmodels.stats.diagnostic.lillifors.html?highlight=lilliefors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo, test de Anderson Darling con scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate([data1, data2, data3]):\n",
    "    #data = ((data - np.mean(data))/np.std(data)).copy() # no requiere estandarización\n",
    "    statistic, critical_value, significance_level = scipy.stats.anderson(data, 'norm')\n",
    "    print(i, statistic)\n",
    "    if statistic > critical_value[significance_level==5.][0]:\n",
    "        display(\"Rechazo la hipótesis nula: nuestros datos no siguen la distribución especificada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia no paramétrica\n",
    "\n",
    "Inferencia: Estimar parámetros o probar hipótesis sobre una población\n",
    "\n",
    "En inferencia **no parámetrica** usamos estadísticos cuya distribución **no depende de supuestos sobre la distribución de la población**\n",
    "\n",
    "- No paramétrico $=$ No asumimos **distribución específica** para la población \n",
    "- No paramétrico $\\neq$ Libre de supuestos (e.g. continuidad, muestras independientes)\n",
    "- No paramétrico $\\neq$ Sin parámetros (e.g. la cantidad de bines de un histograma)\n",
    "\n",
    "Trade-off: \n",
    "\n",
    "- Si sus supuestos se cumplen, los métodos parámetricos son la ópcion de mayor poder estadístico (sensibilidad)\n",
    "- Los métodos no-parámetricos tienen un poder igual o menor pero no requieren de supuestos\n",
    "\n",
    "En clases anteriores vimos\n",
    "\n",
    "- Histograma\n",
    "- Kernel Density Estimation\n",
    "- Bootstrap\n",
    "\n",
    "En esta clase complementaremos con otras herramientas y tests no paramétricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función cuantil y estadístico de orden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La CDF se define como\n",
    "\n",
    "$$\n",
    "P(X<x) = F(x) = p,\n",
    "$$\n",
    "\n",
    "donde $p\\in [0, 1]$\n",
    "\n",
    "En algunos casos nos interesa saber que valor $x$ corresponde a un valor dado $p$\n",
    "\n",
    "Esto se hace con la función cuantil o CDF inversa\n",
    "\n",
    "$$\n",
    "Q(p) = \\inf_{x\\in \\mathbb{R}} p \\leq F(x)\n",
    "$$\n",
    "\n",
    "En scipy podemos calcular $x$ a partir de $p$ usando el atributo `ppf` (percent-point function) de una distribución "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que valor de x corresponde a un 50% de la distribución?\n",
    "display(scipy.stats.norm.ppf(0.5))\n",
    "# y a un 99%?\n",
    "display(scipy.stats.norm.ppf(0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea ${X_1, X_2, X_3, \\ldots, X_N}$ un conjunto de VAs iid y ${x_1, x_2, x_3, \\ldots, x_N}$ una muestra aleatoria\n",
    "\n",
    "Si asumimos que la población tiene una CDF continua (no hay dos VA con el mismo valor) entonces podemos hacer un ordenamiento único\n",
    "\n",
    "$$\n",
    "x_{(1)} < x_{(2)} < x_{(3)} < \\ldots < x_{(N)} \n",
    "$$\n",
    "\n",
    "que se llaman colectivamente el estadístico de orden de la muestra aleatoria y $x_{(r)}$ se llama el estadístico de orden r\n",
    "\n",
    "Con este ordenamiento podemos construir la ECDF\n",
    "\n",
    "$$\n",
    "F_N(x) = \\begin{cases} 0 & x < x_{(1)} \\\\ \n",
    "\\frac{i}{N} & x_{(i-1)} \\leq x < x_{(i)},  i=2,3,\\ldots,N \\\\ \n",
    "1 & x_{(N)} < x\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    n = x.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades de la ECDF\n",
    "\n",
    "El ECDF es un estimador insesgado\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[F_N(x)] = F(x)\n",
    "$$\n",
    "\n",
    "y su varianza tiene a cero con $N$\n",
    "\n",
    "$$\n",
    "\\text{Var}[F_N(x)] = \\frac{1}{N} F(x) ( 1- F(x))\n",
    "$$\n",
    "\n",
    "Adicionalmente la ECDF\n",
    "\n",
    "- es un estimador consistente de $F(x)$ (converge en probabilidad) \n",
    "- (estandarizada) es un asintoticamente normal estándar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función cuantil empírica\n",
    "\n",
    "También podemos usar el estadístico de orden para construir la función cuantil empírica\n",
    "\n",
    "$$\n",
    "Q_N(u) = \\begin{cases}\n",
    "x_{(1)} &  0 < u \\leq \\frac{1}{N} \\\\\n",
    "x_{(2)} & \\frac{1}{N} < u  \\leq\\frac{2}{N} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "x_{(N)} & \\frac{(N-1)}{N} < u  \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000)\n",
    "display(np.quantile(data, 0.5)) # NUMEROS ENTRE 0 Y 1\n",
    "display(np.percentile(data, 50)) # NUMEROS ENTRE 0 Y 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicaciones de estadísticos de orden\n",
    "\n",
    "- El rango es $x_{N} - x_{1}$\n",
    "- La mediana es $x_{(n/2)}$ (n par)\n",
    "\n",
    "Los estadísticos de orden suelen ser más robustos que sus contrapartes en la presencia de *outliers*\n",
    "\n",
    "Podemos calcular la mediana con `np.median`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10) # media cero\n",
    "x[9] = 100\n",
    "display(np.mean(x))\n",
    "display(np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el rango intercuartil, es decir la diferencia entre cuantil 0.75 y 0.25, usando `np.percentile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.std(x))\n",
    "display(np.subtract.reduce(np.quantile(x, [0.75, 0.25])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests no paramétricos\n",
    "\n",
    "El test de KS que vimos antes es un ejemplo de test no paramétrico\n",
    "\n",
    "Las propiedades de la ECDF nos permiten construir distribuciones nulas sin necesidad de asumir una distribución para la población\n",
    "\n",
    "Existen muchos otros tests no-paramétricos, a continuación revisaremos algunos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Mann-Whitney U\n",
    "\n",
    "Es una prueba no-paramétrica para comparar dos **muestras independientes**\n",
    "\n",
    "> Muestras independientes: notas de niños y niñas en una prueba\n",
    "\n",
    "> Muestras dependientes: notas de un mismo curso en dos pruebas\n",
    "\n",
    "El objetivo es probar si provienen de una misma población (en función de su tendencia central)\n",
    "\n",
    "Una forma parámetrica de probar esto es el *t-test* para comparar dos medias $\\mu_0$ y $\\mu_1$. Pero este test asume normalidad\n",
    "\n",
    "El test de Mann-Whitney U en cambio no supone distribución para la población y algunos lo interpretan como una comparación entre medianas\n",
    "\n",
    "La hipótesis nula es que no hay diferencia entre las distribuciones muestrales\n",
    "\n",
    "> La prueba mezcla y ordena las observaciones de ambas muestras. Intutivamente, si las muestras son similares entonces sus observaciones deberían mezclarse en el ordenamiento. Si en cambio se clusterizan entonces las distribuciones son distintas\n",
    "\n",
    "#### Algoritmo\n",
    "\n",
    "1. Ordenar las observaciones de ambas muestras juntas\n",
    "1. Sumar los rangos de la primera muestra $R_1$. $R_2$ queda definida ya que $R_1 + R_2 = \\frac{N(N+1)}{2}$\n",
    "1. Se calcula el estadístico $U_1 = R_1 - \\frac{N_1(N_1+1)}{2}$, donde $N_1$ es el número de observaciones de la primera muestra. Por simetría $U_2$ queda inmediatamente especificado\n",
    "1. Se usa $\\min(U_1, U_2)$ para calcular el p-value\n",
    "\n",
    "Esta prueba requiere al menos 20 observaciones en cada muestra para que sea efectiva\n",
    "\n",
    "La prueba está implementada en [`scipy.stats.mannwhitneyu`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de los rangos con signo de Wilcoxon\n",
    "\n",
    "Si las muestras que se quieren comparar son **dependientes** no se puede usar Mann Whitney U\n",
    "\n",
    "Para esos casos está el test de rango con signo de Wilcoxon\n",
    "\n",
    "Este test funciona como alternativa no-parámetrica al t-test (pareado) cuando los datos violan el supuesto de normalidad\n",
    "\n",
    "Se usa para probar si hubo una diferencia significativa entre el \"antes\" y el \"despues\" de aplicar un tratamiento o intervención\n",
    "\n",
    "Supuestos: \n",
    "\n",
    "- Los datos son continuos\n",
    "- Los datos son pareados y vienen de la misma población\n",
    "- Los pares son independientes y se escogen aleatoriamente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmo\n",
    "\n",
    "Sea entonces $x_{11}, x_{12}, \\ldots, x_{1N}$ y sus pares $x_{21}, x_{22}, \\ldots, x_{2N}$\n",
    "\n",
    "1. Se calculan las diferencias $z_i = x_{2i} - x_{1i}$\n",
    "1. Se ordenan los valores absolutos de las diferencias $|z|_{(1)}, |z|_{(2)}, \\ldots, |z|_{(N)}$ y se reserva el signo de cada diferencia \n",
    "1. Se suman los rangos de las diferencias con signo positivo: $W^{+}$\n",
    "1. Se suman los rangos de las diferencias con signo negativo: $W^{-}$\n",
    "1. El estadístico de prueba es $\\min (W^{+}, W^{-})$ sobre el dataset reducido (se eliminan los $z_{(i)}=0$)\n",
    "\n",
    "La hipótesis nula es que la mediana de las diferencias entre pares de observaciones es nula\n",
    "\n",
    "> Intuitivamente, si la hipótesis nula es cierta, esperariamos que $W^{-}$ y $W^{+}$ sean similares. Si esto no se cumple se esperaría que $W^{+}$ fuera mayor que $W^{-}$\n",
    "\n",
    "El test está implementado en [`scipy.stats.wilcoxon`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otros tests no-parámetricos comunes\n",
    "\n",
    "#### Test de Kruskall-Wallis: Alternativa a one-way ANOVA\n",
    "\n",
    "Probar que existen diferencias significadas en una variable dependiente continua en función de una variable independiente categórica (2 o más grupos) \n",
    "\n",
    "Implementado en [`scipy.stats.kruskal`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html)\n",
    "\n",
    "[Un digerido al respecto de esta y las pruebas que vimos anteriomente](https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kendal $\\tau$: Alternativa al coeficiente de correlación de Pearson\n",
    "\n",
    "Probar si dos variables son estadísticamente dependientes\n",
    "\n",
    "Implementando en [`scipy.stats.kendalltau`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Y que hago si mi estadístico es extraño y no hay un test que me sirva?\n",
    "\n",
    "Puedes obtener la distribución muestral de tu estadístico usando bootstrap\n",
    "\n",
    "Con esto se puede calcular intervalos de confianza y p-values empíricos\n",
    "\n",
    "(Ver clase inferencia estadística)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INFO183",
   "language": "python",
   "name": "info183"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
