
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Bayesian modeling &#8212; Herramientas estadísticas para la investigación</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.5f77b4aec8189eecf79907ce328c390d.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="2. Nonparametric modeling" href="part2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Herramientas estadísticas para la investigación</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Statistical modeling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="part1.html">
   1. Parametric modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="part2.html">
   2. Nonparametric modeling
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Bayesian modeling
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/lectures/2_statistical_modeling/part3.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/magister-informatica-uach/INFO337"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/magister-informatica-uach/INFO337/master?urlpath=tree/lectures/2_statistical_modeling/part3.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   3.1. Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-when-should-i-use-the-bayesian-formalism">
     3.1.1. Why/When should I use the Bayesian formalism?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-bayesian-inference-procedure">
     3.1.2. The Bayesian inference procedure
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-a-posteriori-map-estimation">
   3.2. Maximum
   <em>
    a posteriori
   </em>
   (MAP) estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#priors">
     3.2.1. Priors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-map-of-the-mean-of-a-gaussian-dist">
     3.2.2. Example: MAP of the mean of a Gaussian dist.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#particular-cases">
     3.2.3. Particular cases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-case">
     3.2.4. General case
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extra-map-intepretation-as-a-penalized-mle-regularized-ls">
     3.2.5. Extra: MAP intepretation as a penalized MLE/regularized LS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analytical-posterior-with-conjugate-prior">
   3.3. Analytical posterior with conjugate prior
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interactive-example">
     3.3.1. Interactive example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-the-credible-interval-ci-and-the-high-posterior-density-hpd-regions">
     3.3.2. What are the Credible Interval (CI) and the High Posterior Density (HPD) regions?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conjugate-prior-when-sigma-2-is-unknown">
     3.3.3. Conjugate prior when
     <span class="math notranslate nohighlight">
      \(\sigma^2\)
     </span>
     is unknown
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conjugate-priors-when-mu-and-sigma-2-are-unknown">
     3.3.4. Conjugate priors when
     <span class="math notranslate nohighlight">
      \(\mu\)
     </span>
     and
     <span class="math notranslate nohighlight">
      \(\sigma^2\)
     </span>
     are unknown
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conjugate-priors-for-multivariate-gaussian">
     3.3.5. Conjugate priors for multivariate Gaussian
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-resources">
     3.3.6. More resources
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extra-mean-of-the-posterior">
     3.3.7. Extra: Mean of the posterior
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#future-topics">
   3.4. Future topics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#homework-posterior-for-the-bernoulli-distribution-with-beta-prior">
   3.5. Homework: Posterior for the Bernoulli distribution with Beta prior
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports and matplotlib configuration</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="bayesian-modeling">
<h1><span class="section-number">3. </span>Bayesian modeling<a class="headerlink" href="#bayesian-modeling" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2><span class="section-number">3.1. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p><strong>Recap:</strong> The Bayesian premise</p>
<ul class="simple">
<li><p>Inference is made by producing probability density functions (pdf): <strong>posterior</strong></p></li>
<li><p>Model the uncertainty of the data, experiment, parameters, etc. as a <strong>joint pdf</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> is a R.V., <em>i.e.</em> it follows a distribution: <strong>prior</strong></p></li>
</ul>
<p>The Bayes theorem and the law of total probability tell us</p>
<div class="math notranslate nohighlight">
\[
p(\theta| \{x\}) = \frac{p(\{x\}, \theta)}{p(\{x\})}= \frac{p(\{x\}|\theta) p(\theta)}{\int p(\{x\}|\theta) p(\theta) d\theta} \propto p(\{x\}|\theta) p(\theta),
\]</div>
<ul class="simple">
<li><p>In Bayesian model fitting we seek the <strong>posterior</strong> (parameters given the data)</p></li>
<li><p>The posterior is build from the <strong>likelihood</strong>, <strong>prior</strong> and <strong>evidence</strong> (marginal data likelihood)</p></li>
<li><p>The posterior can be small if either the likelihood or the prior are small</p></li>
</ul>
<div class="section" id="why-when-should-i-use-the-bayesian-formalism">
<h3><span class="section-number">3.1.1. </span>Why/When should I use the Bayesian formalism?<a class="headerlink" href="#why-when-should-i-use-the-bayesian-formalism" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>In many cases the Bayesian inference will not differ much from MLE</p></li>
<li><p>In general the Bayesian inference is harder to compute and requires more sophisticated methods</p></li>
</ul>
<p>Then?</p>
<ul class="simple">
<li><p>We can integrate unknown/missing/uninteresting (nuisance) parameters</p></li>
<li><p>Principled way of injecting prior knowledge (regularization)</p></li>
<li><p>Built-in uncertainty measure on parameters and predictions</p></li>
</ul>
</div>
<div class="section" id="the-bayesian-inference-procedure">
<h3><span class="section-number">3.1.2. </span>The Bayesian inference procedure<a class="headerlink" href="#the-bayesian-inference-procedure" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Formulate data likelihood</p></li>
<li><p>Choose a prior</p></li>
<li><p>Build a joint distribution (relation of all parameters)</p></li>
<li><p>Determine the posterior using Bayes Theorem</p></li>
<li><p>Find MAP and credible regions</p></li>
<li><p>Do hypothesis test</p></li>
<li><p><strong>Criticize:</strong> Evaluate how appropriate the model is and suggest improvements</p></li>
</ol>
</div>
</div>
<div class="section" id="maximum-a-posteriori-map-estimation">
<h2><span class="section-number">3.2. </span>Maximum <em>a posteriori</em> (MAP) estimation<a class="headerlink" href="#maximum-a-posteriori-map-estimation" title="Permalink to this headline">¶</a></h2>
<p>In the Bayesian setting the best “point estimate” of the parameters of the model is given by the MAP</p>
<div class="math notranslate nohighlight">
\[
\hat \theta = \text{arg} \max_\theta p(\theta|\{x\}) =  \text{arg} \max_\theta p(\{x\}| \theta) p(\theta),
\]</div>
<p>where we “omit” the evidence because it does not depend on <span class="math notranslate nohighlight">\(\theta\)</span></p>
<p>Applying the logarithm (monotonic) we can decouple the likelihood from the prior</p>
<div class="math notranslate nohighlight">
\[
\hat \theta = \text{arg} \max_\theta \log p(\{x\}| \theta) + \log p(\theta),
\]</div>
<ul class="simple">
<li><p>MAP estimation is also referred as penalized MLE</p></li>
<li><p>MAP is still a point estimate: poor’s man Bayes</p></li>
</ul>
<div class="section" id="priors">
<h3><span class="section-number">3.2.1. </span>Priors<a class="headerlink" href="#priors" title="Permalink to this headline">¶</a></h3>
<p>Priors summarize what we know about the parameters before-hand, for example</p>
<ul class="simple">
<li><p>a parameter is bounded/unbounded (Normal/Cauchy)</p></li>
<li><p>a parameter is positive (Half-normal, Half-Cauchy, Lognormal, Inverse Gamma)</p></li>
<li><p>a parameter is positive-semidefinite (Inverse Wishart, LKJ)</p></li>
<li><p>a parameter follows a simplex (Dirichlet)</p></li>
</ul>
<p>Priors can be</p>
<ul class="simple">
<li><p>Informative, <em>e.g.</em> my parameter is <span class="math notranslate nohighlight">\(\mathcal{N}(\theta|\mu=5.4, \sigma^2=0.1)\)</span></p></li>
<li><p>Weakly informative, <em>e.g.</em> my parameter is <span class="math notranslate nohighlight">\(\mathcal{N}(\theta|\mu=0, \sigma^2=100.)\)</span></p></li>
<li><p>Uninformative (objective), <em>e.g.</em> my parameter is positive</p></li>
</ul>
<p>Priors should</p>
<ul class="simple">
<li><p>add positive probabilistic weights on possible values</p></li>
<li><p>no weight to impossible values</p></li>
<li><p>help regularize the solution</p></li>
</ul>
<p>Other guidelines to select priors:</p>
<ul class="simple">
<li><p><strong>Conjugate priors:</strong> Given a likelihood the posterior has the same distribution as the prior (more on this later)</p></li>
<li><p>Maximum entropy principle [Murphy 4.1.4]</p></li>
</ul>
<p><strong>More on priors</strong></p>
<ul class="simple">
<li><p>Murphy 5.4</p></li>
<li><p><a class="reference external" href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Stan prior choice recommendations</a></p></li>
</ul>
</div>
<div class="section" id="example-map-of-the-mean-of-a-gaussian-dist">
<h3><span class="section-number">3.2.2. </span>Example: MAP of the mean of a Gaussian dist.<a class="headerlink" href="#example-map-of-the-mean-of-a-gaussian-dist" title="Permalink to this headline">¶</a></h3>
<p>We want to find the MAP for the weight of your professor.</p>
<p>Assuming that the likelihood is Gaussian with known variance we have</p>
<div class="math notranslate nohighlight">
\[
\log p(\{x\}|\theta) = \log L (\mu)  = - \frac{N}{2} \log 2\pi\sigma^2 - \frac{1}{2\sigma^{2}}   \sum_{i=1}^N (x_i-\mu)^2, 
\]</div>
<p>and further assuming that the true weight has a Gaussian prior <span class="math notranslate nohighlight">\(p(\theta)=\mathcal{N}(\mu|\mu_0, \sigma^2_0)\)</span></p>
<div class="math notranslate nohighlight">
\[
\log p(\theta) = -\frac{1}{2} \log 2 \pi \sigma^2_0 - \frac{1}{2 \sigma^2_0}  (\mu - \mu_0)^2,
\]</div>
<p>then we set the derivative to zero</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{d\mu} \log p(\{x\}|\theta) + \log p(\theta) =   \frac{1}{\sigma^{2}}   \sum_{i=1}^N (x_i-\mu)  - \frac{1}{ \sigma^2_0}  (\mu - \mu_0) = 0,
\]</div>
<p>and we get the MAP estimate</p>
<div class="math notranslate nohighlight">
\[
\hat \mu_{\text{map}} =  \left(\frac{N}{\sigma^2} + \frac{1}{\sigma^2_0} \right)^{-1} \left(\frac{N}{\sigma^2} \bar x + \frac{1}{\sigma^2_0} \mu_0 \right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar x = \frac{1}{N} \sum_{i=1}^N x_i\)</span>.</p>
<p><strong>IMPORTANT:</strong> Do not confuse <span class="math notranslate nohighlight">\(\sigma^2\)</span> (the noise variance) and <span class="math notranslate nohighlight">\(\sigma^2_0\)</span> (prior variance)</p>
</div>
<div class="section" id="particular-cases">
<h3><span class="section-number">3.2.3. </span>Particular cases<a class="headerlink" href="#particular-cases" title="Permalink to this headline">¶</a></h3>
<p>The MAP estimator for a  standard normal prior <span class="math notranslate nohighlight">\(\mathcal{N}(\mu| 0, 1)\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\hat \mu_{\text{map}} =  \left(\frac{N}{\sigma^2} + 1 \right)^{-1} \left(\frac{N\bar x}{\sigma^2} \right) = \frac{1}{1 + \sigma^2/N} \bar x,
\]</div>
<p>note that</p>
<div class="math notranslate nohighlight">
\[
\lim_{N \to \infty} \hat \mu_{\text{map}} = \bar x,
\]</div>
<p>which is the MLE solution</p>
<p>Similarly, the MAP estimator for a normal prior <span class="math notranslate nohighlight">\(\mathcal{N}(\mu| 0, \sigma^2_0)\)</span> with <span class="math notranslate nohighlight">\(\sigma^2_0 \to \infty\)</span></p>
<div class="math notranslate nohighlight">
\[
\hat \mu_{\text{map}} =  \left(\frac{N}{\sigma^2} \right)^{-1} \left(\frac{N\bar x}{\sigma^2} \right) =  \bar x,
\]</div>
<p>which is again the MLE solution</p>
<blockquote>
<div><p>Can you explain the intuition behind this particular solutions?</p>
</div></blockquote>
</div>
<div class="section" id="general-case">
<h3><span class="section-number">3.2.4. </span>General case<a class="headerlink" href="#general-case" title="Permalink to this headline">¶</a></h3>
<p>Note that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\hat \mu_{\text{map}}  &amp;=  \left(\frac{N}{\sigma^2} + \frac{1}{\sigma^2_0} \right)^{-1} \left(\frac{N\bar x}{\sigma^2}  + \frac{\mu_0}{\sigma^2_0} \right)  \nonumber \\
&amp;=  \frac{N \bar x \sigma^2_0 + \mu_0 \sigma^2}{N\sigma^2_0+ \sigma^2} = \frac{\bar x + \mu_0 \frac{\sigma^2}{\sigma^2_0 N}}{1 + \frac{\sigma^2}{\sigma^2_0 N}}  \nonumber \\
&amp;= w \bar x + (1-w) \mu_0, \qquad w = \frac{1}{1 + \frac{\sigma^2}{\sigma^2_0 N}}  \nonumber
\end{align}
\end{split}\]</div>
<blockquote>
<div><p>The MAP estimate of the mean is a weighted average between <span class="math notranslate nohighlight">\(\mu_0\)</span> and <span class="math notranslate nohighlight">\(\bar x\)</span> (MLE solution)</p>
</div></blockquote>
<p>If either <span class="math notranslate nohighlight">\(\sigma^2_0\)</span> or <span class="math notranslate nohighlight">\(N\)</span> are large wrt <span class="math notranslate nohighlight">\(\sigma^2\)</span>, then <span class="math notranslate nohighlight">\(w=1\)</span> and the MLE is recovered</p>
<p><strong>Reflect on the following:</strong> The prior has more influence when</p>
<ul class="simple">
<li><p>You have few samples</p></li>
<li><p>Your samples are noisy</p></li>
</ul>
</div>
<div class="section" id="extra-map-intepretation-as-a-penalized-mle-regularized-ls">
<h3><span class="section-number">3.2.5. </span>Extra: MAP intepretation as a penalized MLE/regularized LS<a class="headerlink" href="#extra-map-intepretation-as-a-penalized-mle-regularized-ls" title="Permalink to this headline">¶</a></h3>
<p>The MAP estimate of the mean of a Gaussian dist with known variance using a zero-mean normal prior is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\hat \mu_{\text{map}}  &amp;= \text{arg} \max_\mu  \log p(\{x\}| \mu, \sigma^2) + \log p(\mu) \nonumber \\
&amp;= \text{arg} \max_\mu   - \frac{N}{2} \log 2\pi\sigma^2 - \frac{1}{2\sigma^{2}}   \sum_{i=1}^N (x_i-\mu)^2 -  \frac{1}{2\sigma_0^2} \mu^2 \nonumber \\
&amp;= \text{arg} \min_\mu \frac{1}{2\sigma^{2}}   \sum_{i=1}^N (x_i-\mu)^2 +  \frac{1}{2\sigma_0^2} \mu^2 \nonumber \\
&amp;= \text{arg} \min_\mu \|x-\mu\|^2  + \lambda \|\mu \|^2, \nonumber
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda = \frac{\sigma^2}{\sigma_0^2}\)</span>.</p>
<p>We recognize the last equation as a regularized least squares problem</p>
<ul class="simple">
<li><p>A Gaussian prior yields a L2 regularizer (ridge regression)</p></li>
<li><p>A Laplacian prior yields a L1 regularizer (LASSO)</p></li>
</ul>
<blockquote>
<div><p>For more in these see “3.4 Shrinkage methods”, page 61, Hastie, Tibshirani, Friedman</p>
</div></blockquote>
<p>We will review ridge regression in this course (future class)</p>
</div>
</div>
<div class="section" id="analytical-posterior-with-conjugate-prior">
<h2><span class="section-number">3.3. </span>Analytical posterior with conjugate prior<a class="headerlink" href="#analytical-posterior-with-conjugate-prior" title="Permalink to this headline">¶</a></h2>
<p>The MAP is only a point estimate</p>
<p>For the mean of a Gaussian distribution we can get the full posterior analytically</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p(\theta |\{x\}) &amp;\propto p(\{x\} |\theta ) p(\theta ) \nonumber \\
&amp;\propto \exp \left ( \frac{1}{2\sigma^2} \sum_i (x_i - \mu)^2 \right) \exp \left ( \frac{1}{2\sigma_0^2} (\mu - \mu_0)^2 \right) \nonumber \\
&amp;\propto \exp \left ( -\frac{1}{2 \hat \sigma^2} (\mu - \hat \mu_{\text{map}} )^2 \right),  \nonumber 
\end{align}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\hat \sigma^2 = \left(\frac{N}{\sigma^2} + \frac{1}{\sigma^2_0} \right)^{-1} 
\]</div>
<blockquote>
<div><p>The Gaussian is conjugate to itself</p>
</div></blockquote>
<p>Other way to show this is to use the <a class="reference external" href="http://www.tina-vision.net/docs/memos/2003-003.pdf">property of Gaussian pdf multiplication</a></p>
<div class="math notranslate nohighlight">
\[
\mathcal{N}(x|\mu_1, \sigma_1^2) \mathcal{N}(x|\mu_2, \sigma_2^2) = C \mathcal{N}\left(x\bigg\rvert \frac{\sigma_1^2 \sigma_2^2}{\sigma_1^2 + \sigma_2^2}\left( \frac{\mu_1}{\sigma_1^2} + \frac{\mu_2}{\sigma_2^2}\right), \frac{\sigma_1^2 \sigma_2^2}{\sigma_1^2 + \sigma_2^2}\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> is a scaling constant</p>
<div class="section" id="interactive-example">
<h3><span class="section-number">3.3.1. </span>Interactive example<a class="headerlink" href="#interactive-example" title="Permalink to this headline">¶</a></h3>
<p>Gaussian distributed data with <span class="math notranslate nohighlight">\(\mu=0\)</span> and <span class="math notranslate nohighlight">\(\sigma=1\)</span> is generated</p>
<p>The asymptotic distribution of the MLE (blue) is compared with the posterior (green)</p>
<p>The posterior is computed using a Gaussian prior (orange)</p>
<ul class="simple">
<li><p>What happens with <span class="math notranslate nohighlight">\(N\)</span> grows?</p></li>
<li><p>What happens when <span class="math notranslate nohighlight">\(\sigma_0\)</span> grows?</p></li>
</ul>
<p>We will use <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">Gaussiana</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Signature:       Gaussiana(*args, **kwds)
Type:            norm_gen
String form:     &lt;scipy.stats._continuous_distns.norm_gen object at 0x7f9bc2b94340&gt;
File:            ~/.conda/envs/info183/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py
Docstring:      
A normal continuous random variable.

The location (``loc``) keyword specifies the mean.
The scale (``scale``) keyword specifies the standard deviation.
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s1">&#39;all&#39;</span><span class="p">);</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">mu</span><span class="p">,</span> <span class="n">s2</span> <span class="o">=</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">mu0</span><span class="p">,</span> <span class="n">s20</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="c1"># data</span>
    <span class="n">xi</span> <span class="o">=</span> <span class="n">Gaussiana</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;real $\mu$&#39;</span><span class="p">)</span>
    <span class="c1"># likelihood</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">Gaussiana</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xi</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s2</span><span class="o">/</span><span class="n">N</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MLE&#39;</span><span class="p">);</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c1"># prior</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">Gaussiana</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s20</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;prior&#39;</span><span class="p">);</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c1"># posterior</span>
    <span class="n">s2_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="n">s2</span> <span class="o">+</span> <span class="mf">1.</span><span class="o">/</span><span class="n">s20</span><span class="p">)</span><span class="o">**-</span><span class="mi">1</span>
    <span class="n">mu_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span><span class="o">/</span><span class="n">s2</span> <span class="o">+</span> <span class="n">mu0</span><span class="o">/</span><span class="n">s20</span><span class="p">)</span><span class="o">*</span><span class="n">s2_pos</span><span class="p">;</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">Gaussiana</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu_pos</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s2_pos</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;posterior&#39;</span><span class="p">);</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">posterior</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>    
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>    
    <span class="n">display</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Credible interval for mu: [</span><span class="si">{</span><span class="n">posterior</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">posterior</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>

<span class="n">widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> 
         <span class="n">mu0</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\mu_0$&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.</span><span class="p">),</span> 
         <span class="n">s20</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\sigma_0^2$&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">1.</span><span class="p">),</span>
         <span class="n">N</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">SelectionSlider</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="mi">10</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "54e1779d0c764c13b662e5739f31578f", "version_major": 2, "version_minor": 0}
</script><img alt="../../_images/part3_14_1.png" src="../../_images/part3_14_1.png" />
</div>
</div>
</div>
<div class="section" id="what-are-the-credible-interval-ci-and-the-high-posterior-density-hpd-regions">
<h3><span class="section-number">3.3.2. </span>What are the Credible Interval (CI) and the High Posterior Density (HPD) regions?<a class="headerlink" href="#what-are-the-credible-interval-ci-and-the-high-posterior-density-hpd-regions" title="Permalink to this headline">¶</a></h3>
<p>One way to summarize the posterior is to measure its <strong>width</strong></p>
<p>The <span class="math notranslate nohighlight">\(100(1-\alpha)\)</span> % CI of <span class="math notranslate nohighlight">\(\theta\)</span> is a contiguous region <span class="math notranslate nohighlight">\([\theta_{l}, \theta_{u}]\)</span> such that</p>
<div class="math notranslate nohighlight">
\[
P(\theta_{l}&lt; \theta &lt; \theta_{u}) = 1 - \alpha
\]</div>
<p>We have to either know the functional form of the posterior (Analytical) or have a posterior from which we can sample (MCMC)</p>
<p>The HPD is an alternative to CI that is better when we have multiple modes</p>
<p>The HPD depends on the height of the posterior</p>
<p><img alt="image.png" src="lectures/2_statistical_modeling/attachment:image.png" /></p>
<blockquote>
<div><p>See Murphy 5.2 for more details</p>
</div></blockquote>
</div>
<div class="section" id="conjugate-prior-when-sigma-2-is-unknown">
<h3><span class="section-number">3.3.3. </span>Conjugate prior when <span class="math notranslate nohighlight">\(\sigma^2\)</span> is unknown<a class="headerlink" href="#conjugate-prior-when-sigma-2-is-unknown" title="Permalink to this headline">¶</a></h3>
<p>Assuming that the mean <span class="math notranslate nohighlight">\(\mu\)</span> is known the conjugate prior for the variance is an inverse-Gamma distribution</p>
<div class="math notranslate nohighlight">
\[
p(\sigma^2) = \text{IG}(\sigma^2| \alpha_0, \beta_0) = \frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} x^{-\alpha_0-1} e^{-\frac{\beta_0}{x}}
\]</div>
<p>And the resulting posterior is also</p>
<div class="math notranslate nohighlight">
\[
\text{IG}\left(\sigma^2| \alpha_N , \beta_N  \right)
\]</div>
<p>with</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \alpha_N = \alpha_0 + N/2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_N = \beta_0 + \frac{1}{2} \sum_{i=1}^N (x_i - \mu)^2\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">invgamma</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">invgamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> 
                    <span class="n">invgamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">px</span> <span class="o">=</span> <span class="n">invgamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">px</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">px</span><span class="p">)</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">px</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">])</span>  
    
<span class="n">widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">10.0</span><span class="p">),</span> 
         <span class="n">b</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">10.0</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "d6de00f166c74a11bddd578edd781b99", "version_major": 2, "version_minor": 0}
</script><img alt="../../_images/part3_17_1.png" src="../../_images/part3_17_1.png" />
</div>
</div>
<p>As both <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> encode the strength of the prior the following parameterization is broadly used</p>
<div class="math notranslate nohighlight">
\[
p(\sigma^2) = \text{IG}(\sigma^2| \alpha, \beta) = \text{IG}\left(\sigma^2| \frac{\nu}{2}, \frac{\nu \sigma_0^2}{2}\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_0^2\)</span> controls the value of the prior and <span class="math notranslate nohighlight">\(\nu\)</span> the strength</p>
<p>This is also closely related to the <a class="reference external" href="https://en.wikipedia.org/wiki/Inverse-chi-squared_distribution">inverse chi-square distribution</a></p>
</div>
<div class="section" id="conjugate-priors-when-mu-and-sigma-2-are-unknown">
<h3><span class="section-number">3.3.4. </span>Conjugate priors when <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span> are unknown<a class="headerlink" href="#conjugate-priors-when-mu-and-sigma-2-are-unknown" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Multiplying the normal prior and the IG prior does not yield a conjugate prior (assumes independence of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>)</p></li>
<li><p>In this case the conjugate prior is hierarchical</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p(x_i|\mu, \sigma^2) &amp;= \mathcal{N}(\mu, \sigma^2)  \nonumber \\
p(\mu|\sigma^2) &amp;= \mathcal{N}(\mu_0, \sigma^2/\lambda_0)  \nonumber \\
p(\sigma^2) &amp;= \text{IG}(\alpha, \beta)  \nonumber
\end{align}
\end{split}\]</div>
<p>which is called <strong>normal-inverse-gamma (NIG)</strong>, a four parameter distribution</p>
<p>The NIG prior is</p>
<div class="math notranslate nohighlight">
\[
p(\mu, \sigma^2) = \text{NIG}(\mu_0, \lambda_0, \alpha_0, \beta_0) = \mathcal{N}(\mu|\mu_0 , \sigma^2/\lambda_0) \text{IG}(\sigma^2|\alpha_0, \beta_0)
\]</div>
<p>An the posterior is also NIG</p>
<div class="math notranslate nohighlight">
\[
p(\mu, \sigma^2|\{x\}) =  \text{NIG}(\mu_n, \lambda_n, \alpha_n, \beta_n)
\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda_n = \lambda_0 + N\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_n = \lambda_n^{-1} \left ( \lambda_0 \mu_0  + N \bar x \right)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha_n = \alpha_0 + N/2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_n = \beta_0 + 0.5\mu_0^2\lambda_0 + 0.5\sum_i x_i^2 - 0.5\lambda_n \mu_n^2\)</span></p></li>
</ul>
</div>
<div class="section" id="conjugate-priors-for-multivariate-gaussian">
<h3><span class="section-number">3.3.5. </span>Conjugate priors for multivariate Gaussian<a class="headerlink" href="#conjugate-priors-for-multivariate-gaussian" title="Permalink to this headline">¶</a></h3>
<p>We use the Inverse Wishart (IW), a multidimensional generalization of Inverse Gamma</p>
<p>IW is a distribution over positive semi-definite matrices: covariance</p>
<p>See Murphy 4.5 &amp; 4.6 for more details</p>
</div>
<div class="section" id="more-resources">
<h3><span class="section-number">3.3.6. </span>More resources<a class="headerlink" href="#more-resources" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Document by Kevin Murphy on conjugate priors for the Gaussian dist: <a class="reference external" href="https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf">https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf</a></p></li>
<li><p>More examples on conjugate priors, Bayesian updates and a bit on model selection: <a class="reference external" href="https://github.com/magister-informatica-uach/INFO3XX/blob/master/0_probabilities_inference.ipynb">https://github.com/magister-informatica-uach/INFO3XX/blob/master/0_probabilities_inference.ipynb</a></p></li>
<li><p>More on Bayesian model selection: Murphy 5.3</p></li>
</ul>
</div>
<div class="section" id="extra-mean-of-the-posterior">
<h3><span class="section-number">3.3.7. </span>Extra: Mean of the posterior<a class="headerlink" href="#extra-mean-of-the-posterior" title="Permalink to this headline">¶</a></h3>
<p>Other point estimate that can be used to characterize the posterior is</p>
<div class="math notranslate nohighlight">
\[
\hat \theta = \mathbb{E}[\theta|\{x\}] = \int \theta p(\theta| \{x\}) d\theta,
\]</div>
<p><em>i.e.</em> the mean or expected value of the posterior</p>
</div>
</div>
<div class="section" id="future-topics">
<h2><span class="section-number">3.4. </span>Future topics<a class="headerlink" href="#future-topics" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Empirical Bayes: Model in which the hyperparameters are estimated from data instead of fixed before-hand</p></li>
<li><p>Hierarchical Bayes: Hyper-priors assigned to the parameters of the priors</p></li>
<li><p>Markov Chain Monte Carlo (MCMC): Algorithm to sample from a distribution. We will use it to learn complex Bayesian models</p></li>
</ul>
</div>
<div class="section" id="homework-posterior-for-the-bernoulli-distribution-with-beta-prior">
<h2><span class="section-number">3.5. </span>Homework: Posterior for the Bernoulli distribution with Beta prior<a class="headerlink" href="#homework-posterior-for-the-bernoulli-distribution-with-beta-prior" title="Permalink to this headline">¶</a></h2>
<p>Consider the “magic coin” example from our previous lecture. Once again we a assume a Bernoulli distribution for a coin toss</p>
<div class="math notranslate nohighlight">
\[
\text{Bernoulli}(x|p) = p^x (1-p)^{1-x}, ~~ x \in \{0, 1\}
\]</div>
<p>where <span class="math notranslate nohighlight">\(p\)</span> is the probability of <span class="math notranslate nohighlight">\(x=1\)</span></p>
<p>Your friend tosses the coin N times and records the outputs <span class="math notranslate nohighlight">\(\{x_i\}\)</span> which are given by</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>coins = scipy.stats.binom.rvs(n=1, p=0.75, random_state=1234, size=100)
</pre></div>
</div>
<p>Assume a beta prior for the parameter <span class="math notranslate nohighlight">\(p\)</span></p>
<div class="math notranslate nohighlight">
\[
\text{Beta}(p|\alpha, \beta) = \frac{p^{\alpha-1} (1-p)^{\beta-1}}{\text{B}(\alpha, \beta)}  
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\text{B}(x, y) = \int_0^1 z^{x-1} (1-z)^{y-1} \,dz
\]</div>
<ul class="simple">
<li><p>Write the likelihood and find an analytic expression for the MAP estimate of <span class="math notranslate nohighlight">\(p\)</span></p></li>
<li><p>Bernoulli and Beta are conjugate distributions. Find an analytic expression for the posterior of <span class="math notranslate nohighlight">\(p\)</span> given <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>For the first 10 and 100 coins and assuming <span class="math notranslate nohighlight">\(\alpha=\beta=2\)</span></p>
<ul>
<li><p>Plot the asymptotic distribution of the MLE of <span class="math notranslate nohighlight">\(p\)</span> and the posterior of <span class="math notranslate nohighlight">\(p\)</span> and the prior of <span class="math notranslate nohighlight">\(p\)</span></p></li>
<li><p>Print the credible interval of the posterior of <span class="math notranslate nohighlight">\(p\)</span></p></li>
</ul>
</li>
<li><p>Repeat for <span class="math notranslate nohighlight">\(\alpha=\beta=0.5\)</span>.</p></li>
<li><p>Compare and discuss your results</p></li>
</ul>
</div>
</div>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"12f4d21e82d8444ca3b596df7047e77d": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "19475176cd27419195dd426fa3a3863c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2c8285fb832b4f57897301948b9dd0a9": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "$\\mu_0$", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_12f4d21e82d8444ca3b596df7047e77d", "max": 3.0, "min": -3.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_b946be353bfd4a40a10599f87c698c1f", "value": 0.0}}, "2d54ef4fc78946c99f0604195997340c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3dcd05ddfff04cbea8e17a2a6f0ef87c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "48f55d11848b4a46a7636e50438aaf6e": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "53714f98e9ef409c903070f57be168ff": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "54e1779d0c764c13b662e5739f31578f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_2c8285fb832b4f57897301948b9dd0a9", "IPY_MODEL_cb444a5fb7454922be1ed591cfeaad13", "IPY_MODEL_f5426d9626b545fe95b609aa2b4c9de4", "IPY_MODEL_d0a35e92f24646c6b193fa400a33e74d"], "layout": "IPY_MODEL_3dcd05ddfff04cbea8e17a2a6f0ef87c"}}, "8d5757957629414ea09909263c519ac7": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a59d08319be7496d81cdb32a42e44f8c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "af081a4191b44b359e4acd65ed104799": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b1dc8bfc192a4f88bfa18dd7669b62f4": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b946be353bfd4a40a10599f87c698c1f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "c0bd875eb82046ceaf2c6f9a51ad8839": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "a", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_a59d08319be7496d81cdb32a42e44f8c", "max": 10.0, "min": 0.01, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_c8547969f9244384b3512f879405ea1d", "value": 0.01}}, "c8547969f9244384b3512f879405ea1d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "cb444a5fb7454922be1ed591cfeaad13": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "$\\sigma_0^2$", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_af081a4191b44b359e4acd65ed104799", "max": 10.0, "min": 0.1, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_ddbc76e605fb4e5395d56f12b2900988", "value": 1.0}}, "d0a35e92f24646c6b193fa400a33e74d": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_48f55d11848b4a46a7636e50438aaf6e", "msg_id": "", "outputs": [{"data": {"text/plain": "'Credible interval for mu: [1.8982, 3.0801]'"}, "metadata": {}, "output_type": "display_data"}]}}, "d6de00f166c74a11bddd578edd781b99": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_c0bd875eb82046ceaf2c6f9a51ad8839", "IPY_MODEL_eb5da48208a9495c9bd3ee96dca0dd13", "IPY_MODEL_fee78a1a357a4936b4557e018a405bec"], "layout": "IPY_MODEL_19475176cd27419195dd426fa3a3863c"}}, "ddbc76e605fb4e5395d56f12b2900988": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "eb5da48208a9495c9bd3ee96dca0dd13": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "b", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_8d5757957629414ea09909263c519ac7", "max": 10.0, "min": 0.01, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_f9e1c81fa1fc4e57af1c86f2e71c4caf", "value": 0.01}}, "f5426d9626b545fe95b609aa2b4c9de4": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SelectionSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SelectionSliderModel", "_options_labels": ["1", "2", "5", "10", "20", "50", "100"], "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "SelectionSliderView", "continuous_update": true, "description": "N", "description_tooltip": null, "disabled": false, "index": 3, "layout": "IPY_MODEL_53714f98e9ef409c903070f57be168ff", "orientation": "horizontal", "readout": true, "style": "IPY_MODEL_2d54ef4fc78946c99f0604195997340c"}}, "f9e1c81fa1fc4e57af1c86f2e71c4caf": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "fee78a1a357a4936b4557e018a405bec": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_b1dc8bfc192a4f88bfa18dd7669b62f4", "msg_id": "", "outputs": []}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures/2_statistical_modeling"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="part2.html" title="previous page"><span class="section-number">2. </span>Nonparametric modeling</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Pablo Huijse and Eliana Scheihing<br/>
        
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>